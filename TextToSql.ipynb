{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45feffac",
   "metadata": {},
   "source": [
    "# Decoder Only Transformer\n",
    "\n",
    "- 18 Million trainable Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "d09a8a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from datasets import load_dataset\n",
    "import json\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import pad_sequences\n",
    "from keras import layers\n",
    "from keras import models\n",
    "import numpy as np\n",
    "from keras import mixed_precision\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "769b0161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "print(tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "\n",
    "policy = mixed_precision.Policy('mixed_float16')\n",
    "mixed_precision.set_global_policy(policy)\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "else:\n",
    "    print(\"Bruh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "542714f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset preparation\n",
    "dataset = load_dataset(\"Clinton/Text-to-sql-v1\")\n",
    "training = dataset[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "9beffdb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Name the home team for carlton away team\n",
      "Context: CREATE TABLE table_name_77 (\n",
      "    home_team VARCHAR,\n",
      "    away_team VARCHAR\n",
      ")\n",
      "SELECT home_team FROM table_name_77 WHERE away_team = \"carlton\"\n"
     ]
    }
   ],
   "source": [
    "\n",
    "input_text = []\n",
    "target_text = []\n",
    "\n",
    "for sample in training:\n",
    "  input = \"Question: \" + sample[\"instruction\"] + \"\\n\" + \"Context: \" + sample[\"input\"]\n",
    "  input_text.append(input)\n",
    "  target_text.append(sample[\"response\"])\n",
    "\n",
    "print(input_text[0])\n",
    "print(target_text[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "f6dc829b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "397386\n",
      "876\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tokenizer = Tokenizer(num_words= 25000, oov_token=\"<OOV>\", char_level=False,lower=False,filters=\"\",split=\" \" )\n",
    "\n",
    "texts = [f\"<Start> {inp} <Sep> {sql} <End>\" for inp, sql in zip(input_text, target_text)]\n",
    "\n",
    "\n",
    "tokenizer.fit_on_texts(texts) # train on both at same time because Decoder only model\n",
    "print(len(tokenizer.word_index))\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "max_seq_len = max(len(seq) for seq in sequences)\n",
    "print(max_seq_len)\n",
    "sequences = pad_sequences(sequences,max_seq_len,padding=\"post\") \n",
    "\n",
    "vocab_size = 25000\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "bf6662ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"decoder_only_transformer\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_13 (InputLayer)          [(None, 875)]        0           []                               \n",
      "                                                                                                  \n",
      " Embedding_layer (Embedding)    (None, 875, 256)     6400000     ['input_13[0][0]']               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_99 (TFOpL  (None, 875, 256)    0           ['Embedding_layer[0][0]']        \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " self_attemtion_0 (MultiHeadAtt  (None, 875, 256)    263168      ['tf.__operators__.add_99[0][0]',\n",
      " ention)                                                          'tf.__operators__.add_99[0][0]',\n",
      "                                                                  'tf.__operators__.add_99[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_100 (TFOp  (None, 875, 256)    0           ['self_attemtion_0[0][0]',       \n",
      " Lambda)                                                          'tf.__operators__.add_99[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_88 (LayerN  (None, 875, 256)    512         ['tf.__operators__.add_100[0][0]'\n",
      " ormalization)                                                   ]                                \n",
      "                                                                                                  \n",
      " feed_forward_0 (Sequential)    (None, 875, 256)     525568      ['layer_normalization_88[0][0]'] \n",
      "                                                                                                  \n",
      " tf.__operators__.add_101 (TFOp  (None, 875, 256)    0           ['feed_forward_0[0][0]',         \n",
      " Lambda)                                                          'layer_normalization_88[0][0]'] \n",
      "                                                                                                  \n",
      " layer_normalization_89 (LayerN  (None, 875, 256)    512         ['tf.__operators__.add_101[0][0]'\n",
      " ormalization)                                                   ]                                \n",
      "                                                                                                  \n",
      " self_attemtion_1 (MultiHeadAtt  (None, 875, 256)    263168      ['layer_normalization_89[0][0]', \n",
      " ention)                                                          'layer_normalization_89[0][0]', \n",
      "                                                                  'layer_normalization_89[0][0]'] \n",
      "                                                                                                  \n",
      " tf.__operators__.add_102 (TFOp  (None, 875, 256)    0           ['self_attemtion_1[0][0]',       \n",
      " Lambda)                                                          'layer_normalization_89[0][0]'] \n",
      "                                                                                                  \n",
      " layer_normalization_90 (LayerN  (None, 875, 256)    512         ['tf.__operators__.add_102[0][0]'\n",
      " ormalization)                                                   ]                                \n",
      "                                                                                                  \n",
      " feed_forward_1 (Sequential)    (None, 875, 256)     525568      ['layer_normalization_90[0][0]'] \n",
      "                                                                                                  \n",
      " tf.__operators__.add_103 (TFOp  (None, 875, 256)    0           ['feed_forward_1[0][0]',         \n",
      " Lambda)                                                          'layer_normalization_90[0][0]'] \n",
      "                                                                                                  \n",
      " layer_normalization_91 (LayerN  (None, 875, 256)    512         ['tf.__operators__.add_103[0][0]'\n",
      " ormalization)                                                   ]                                \n",
      "                                                                                                  \n",
      " self_attemtion_2 (MultiHeadAtt  (None, 875, 256)    263168      ['layer_normalization_91[0][0]', \n",
      " ention)                                                          'layer_normalization_91[0][0]', \n",
      "                                                                  'layer_normalization_91[0][0]'] \n",
      "                                                                                                  \n",
      " tf.__operators__.add_104 (TFOp  (None, 875, 256)    0           ['self_attemtion_2[0][0]',       \n",
      " Lambda)                                                          'layer_normalization_91[0][0]'] \n",
      "                                                                                                  \n",
      " layer_normalization_92 (LayerN  (None, 875, 256)    512         ['tf.__operators__.add_104[0][0]'\n",
      " ormalization)                                                   ]                                \n",
      "                                                                                                  \n",
      " feed_forward_2 (Sequential)    (None, 875, 256)     525568      ['layer_normalization_92[0][0]'] \n",
      "                                                                                                  \n",
      " tf.__operators__.add_105 (TFOp  (None, 875, 256)    0           ['feed_forward_2[0][0]',         \n",
      " Lambda)                                                          'layer_normalization_92[0][0]'] \n",
      "                                                                                                  \n",
      " layer_normalization_93 (LayerN  (None, 875, 256)    512         ['tf.__operators__.add_105[0][0]'\n",
      " ormalization)                                                   ]                                \n",
      "                                                                                                  \n",
      " self_attemtion_3 (MultiHeadAtt  (None, 875, 256)    263168      ['layer_normalization_93[0][0]', \n",
      " ention)                                                          'layer_normalization_93[0][0]', \n",
      "                                                                  'layer_normalization_93[0][0]'] \n",
      "                                                                                                  \n",
      " tf.__operators__.add_106 (TFOp  (None, 875, 256)    0           ['self_attemtion_3[0][0]',       \n",
      " Lambda)                                                          'layer_normalization_93[0][0]'] \n",
      "                                                                                                  \n",
      " layer_normalization_94 (LayerN  (None, 875, 256)    512         ['tf.__operators__.add_106[0][0]'\n",
      " ormalization)                                                   ]                                \n",
      "                                                                                                  \n",
      " feed_forward_3 (Sequential)    (None, 875, 256)     525568      ['layer_normalization_94[0][0]'] \n",
      "                                                                                                  \n",
      " tf.__operators__.add_107 (TFOp  (None, 875, 256)    0           ['feed_forward_3[0][0]',         \n",
      " Lambda)                                                          'layer_normalization_94[0][0]'] \n",
      "                                                                                                  \n",
      " layer_normalization_95 (LayerN  (None, 875, 256)    512         ['tf.__operators__.add_107[0][0]'\n",
      " ormalization)                                                   ]                                \n",
      "                                                                                                  \n",
      " decoder_output_dense (Dense)   (None, 875, 25000)   6425000     ['layer_normalization_95[0][0]'] \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 15,984,040\n",
      "Trainable params: 15,984,040\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "  311/52442 [..............................] - ETA: 2:08:32 - loss: 1.2623 - accuracy: 0.8690"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_28680\\886108102.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m \u001b[1;31m# Trainings settings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     87\u001b[0m \u001b[0membed_dim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m256\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[0mnum_heads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[0mff_dim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1024\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Henri\\miniconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;31m# To get the full stack trace, call:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[1;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m             \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\Henri\\miniconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1634\u001b[0m             \u001b[1;31m# If eval data_handler exists, delete it after all epochs are done.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1635\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"_eval_data_handler\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1636\u001b[0m                 \u001b[1;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_eval_data_handler\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1637\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1638\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\Henri\\miniconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    466\u001b[0m             \u001b[0mbatch\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mInteger\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[0mof\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0mwithin\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcurrent\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    467\u001b[0m             \u001b[0mlogs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mDict\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mAggregated\u001b[0m \u001b[0mmetric\u001b[0m \u001b[0mresults\u001b[0m \u001b[0mup\u001b[0m \u001b[0muntil\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    468\u001b[0m         \"\"\"\n\u001b[0;32m    469\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 470\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"end\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\Henri\\miniconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[0;32m    313\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    314\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"begin\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    315\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    316\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"end\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 317\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    318\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    319\u001b[0m             raise ValueError(\n\u001b[0;32m    320\u001b[0m                 \u001b[1;34mf\"Unrecognized hook: {hook}. \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Henri\\miniconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, mode, batch, logs)\u001b[0m\n\u001b[0;32m    336\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_timing\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mbatch\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    337\u001b[0m             \u001b[0mbatch_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    338\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    339\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 340\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    341\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    342\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    343\u001b[0m             \u001b[0mend_hook_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Henri\\miniconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[0;32m    384\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    385\u001b[0m         \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_process_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_batch_hook\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    387\u001b[0m             \u001b[0mhook\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 388\u001b[1;33m             \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    389\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    390\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    391\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhook_name\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_hook_times\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Henri\\miniconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    755\u001b[0m             \u001b[0mbatch\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mInteger\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[0mof\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0mwithin\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcurrent\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    756\u001b[0m             \u001b[0mlogs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mDict\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mAggregated\u001b[0m \u001b[0mmetric\u001b[0m \u001b[0mresults\u001b[0m \u001b[0mup\u001b[0m \u001b[0muntil\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    757\u001b[0m         \"\"\"\n\u001b[0;32m    758\u001b[0m         \u001b[1;31m# For backwards compatibility.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 759\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_28680\\886108102.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(batch, logs)\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m         \u001b[0mon_batch_end\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclip_by_global_norm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mv\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\Henri\\miniconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 155\u001b[1;33m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\Henri\\miniconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1180\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop_dispatch_handler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1181\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mOpDispatcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNOT_SUPPORTED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1182\u001b[0m           \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1183\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1184\u001b[1;33m           \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\Henri\\miniconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\clip_ops.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(t_list, clip_norm, use_norm, name)\u001b[0m\n\u001b[0;32m    369\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    370\u001b[0m           values_clipped.append(\n\u001b[0;32m    371\u001b[0m               array_ops.identity(v * scale, name=\"%s_%d\" % (name, i)))\n\u001b[0;32m    372\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 373\u001b[1;33m     list_clipped = [\n\u001b[0m\u001b[0;32m    374\u001b[0m         \u001b[0mindexed_slices\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIndexedSlices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_v\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdense_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    375\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexed_slices\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIndexedSlices\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mc_v\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    376\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mc_v\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues_clipped\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Henri\\miniconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 155\u001b[1;33m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\Henri\\miniconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1180\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop_dispatch_handler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1181\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mOpDispatcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNOT_SUPPORTED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1182\u001b[0m           \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1183\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1184\u001b[1;33m           \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\Henri\\miniconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(input, name)\u001b[0m\n\u001b[0;32m    290\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"graph\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m     \u001b[1;31m# Make sure we get an input with handle data attached from resource\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    292\u001b[0m     \u001b[1;31m# variables. Variables have correct handle data when graph building.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    293\u001b[0m     \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 294\u001b[1;33m   \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    295\u001b[0m   \u001b[1;31m# Propagate handle data for happier shape inference for resource variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    296\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"_handle_data\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m     \u001b[0mret\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_data\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Henri\\miniconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(input, name)\u001b[0m\n\u001b[0;32m   4070\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4071\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4072\u001b[0m       \u001b[0m_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4073\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4074\u001b[1;33m       \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4075\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4076\u001b[0m       return identity_eager_fallback(\n\u001b[0;32m   4077\u001b[0m           input, name=name, ctx=_ctx)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Trainings settings\n",
    "embed_dim = 256\n",
    "num_heads = 8 \n",
    "ff_dim = 1024\n",
    "num_layers = 4\n",
    "\n",
    "inputs = layers.Input(shape=(max_seq_len-1))\n",
    "embedding_layer = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim,mask_zero=True, name=\"Embedding_layer\")(inputs)\n",
    "positional_encoding = layers.Embedding(input_dim=max_seq_len-1,output_dim=embed_dim, name=\"postional_encoding_layer\")(tf.range(start=0, limit=max_seq_len-1,delta=1))\n",
    "\n",
    "x = embedding_layer + positional_encoding\n",
    "\n",
    "for i in range(num_layers):\n",
    "  selfAttention = layers.MultiHeadAttention(num_heads=num_heads,key_dim=embed_dim//num_heads,dropout=0.1,name=f\"self_attemtion_{i}\")(query=x,value=x,key=x, use_causal_mask=True)\n",
    "\n",
    "  x1 = layers.LayerNormalization(epsilon=1e-6)(selfAttention + x)\n",
    "\n",
    "  ffn = keras.Sequential([\n",
    "    layers.Dense(ff_dim,activation=\"gelu\"),\n",
    "    layers.Dropout(0.1),\n",
    "    layers.Dense(embed_dim)\n",
    "  ], name=f\"feed_forward_{i}\")\n",
    "\n",
    "  ffn_output = ffn(x1)\n",
    "\n",
    "  x = layers.LayerNormalization(epsilon=1e-6)(ffn_output + x1)\n",
    "\n",
    "outputs = layers.Dense(\n",
    "  vocab_size,\n",
    "  activation=\"softmax\",\n",
    "  name=\"decoder_output_dense\"\n",
    ")(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs, name=\"decoder_only_transformer\")\n",
    "\n",
    "initial_learning_rate = 1e-5\n",
    "lr_schedule = keras.optimizers.schedules.CosineDecay(\n",
    "    initial_learning_rate=initial_learning_rate,\n",
    "    decay_steps=1000,\n",
    "    alpha=0.1\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_loss\",\n",
    "        patience=5,  \n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    \n",
    "    keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=3,\n",
    "        min_lr=1e-7,\n",
    "        verbose=1\n",
    "    ),\n",
    "    \n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath='TextToSQL.keras',\n",
    "        monitor='val_loss',\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    \n",
    "    keras.callbacks.LambdaCallback(\n",
    "        on_batch_end=lambda batch, logs: tf.clip_by_global_norm([v for v in model.trainable_variables], 1.0)\n",
    "    )\n",
    "]\n",
    "\n",
    "X = sequences[:, :-1]  \n",
    "y = sequences[:, 1:]   \n",
    "\n",
    "\n",
    "batch_size = 4\n",
    "validation_split = 0.2 \n",
    "\n",
    "history = model.fit(\n",
    "    X,\n",
    "    y,\n",
    "    batch_size=batch_size,\n",
    "    epochs=1,\n",
    "    validation_split=validation_split,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9ef569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference Step\n",
    "textToSQL = keras.models.load_model('TextToSQL.keras')\n",
    "def generateTextToSQL(prompt):\n",
    "    prompt = \"<Start> \" + prompt + \"<Sep>\"\n",
    "    \n",
    "    input_sequence = tokenizer.texts_to_sequences([prompt])[0]\n",
    "    current_sequence = pad_sequences([input_sequence], maxlen=max_seq_len-1, padding='post')\n",
    "    \n",
    "    generated_tokens = []\n",
    "    for _ in range(100):  \n",
    "        predictions = textToSQL.predict(current_sequence, verbose=0)\n",
    "        next_token = np.argmax(predictions[0, len(input_sequence) + len(generated_tokens) - 1])\n",
    "        \n",
    "        if next_token == tokenizer.word_index.get(\"<End<\", 0) or next_token == 0:\n",
    "            break\n",
    "            \n",
    "        generated_tokens.append(next_token)\n",
    "        \n",
    "        new_sequence = input_sequence + generated_tokens\n",
    "        current_sequence = pad_sequences([new_sequence], maxlen=max_seq_len-1, padding='post')\n",
    "    \n",
    "    result = [tokenizer.index_word.get(token, \"\") for token in generated_tokens]\n",
    "    return \" \".join(result)\n",
    "\n",
    "test_prompt = \"\"\"\n",
    " Question: How many heads of the departments are older than 56 ? \n",
    " Table department: Department_ID number, Name text, Creation text, Ranking number, Budget_in_Billions number, Num_Employees number | Table head: head_ID number, name text, born_state text, age number | Table management: department_ID number, head_ID number, temporary_acting text\n",
    " \"\"\"\n",
    "generated = generateTextToSQL(test_prompt)\n",
    "print(\"Generated SQL Code:\", generated)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
